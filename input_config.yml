embedding_models:
  - apple/aimv2-large-patch14-224
  - apple/aimv2-huge-patch14-224
  - apple/aimv2-1B-patch14-224
  - apple/aimv2-3B-patch14-224
  - apple/aimv2-large-patch14-336
  - apple/aimv2-huge-patch14-336
  - apple/aimv2-1B-patch14-336
  - apple/aimv2-3B-patch14-336
  - apple/aimv2-large-patch14-448
  - apple/aimv2-huge-patch14-448
  - apple/aimv2-1B-patch14-448
  - apple/aimv2-3B-patch14-448
  - apple/aimv2-large-patch14-224-distilled
  - apple/aimv2-large-patch14-336-distilled
  - apple/aimv2-large-patch14-native

model:
  field: model_name
  label: Embedding Model
  description: Select from one of the supported models. Note: The model weights will be downloaded from Hugging Face.
  dropdown_label: Choose the AIMv2 embedding model you want to use
  required: true

embedding_types:
  field: embedding_types
  label: Which embedding approach do you want to use?
  required: true
  choices:
    cls:
      label: Class token embedding
      description: A single embedding vector derived from special classification token. Represents the global semantic context of an image.
    mean:
      label: Mean pooling embedding
      description: An embedding vector computed by averaging the representations of all image patches. Captures distributed contextual information across the entire input.

embedding_field:
  field: emb_field
  required: true
  description: Name of the field to store the embeddings in.

delegate:
  field: delegate
  default: false
  required: true
  label: Delegate execution?
  description: If you choose to delegate this operation you must first have a delegated service running. You can launch a delegated service by running `fiftyone delegated launch` in your terminal